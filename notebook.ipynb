{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ’­ğŸŒŒğŸ”‘"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:ì¸ì…‰ì…˜ -> ğŸ’­ğŸŒŒğŸ”‘\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš¢ğŸ’”ğŸŒŠ"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:íƒ€ì´íƒ€ë‹‰ -> ğŸš¢ğŸ’”ğŸŒŠ\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain.memory import ConversationSummaryBufferMemory\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "#from langchain.chains import LLMChain\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "from langchain.prompts import MessagesPlaceholder,ChatPromptTemplate\n",
    "from langchain.callbacks import StreamingStdOutCallbackHandler\n",
    "from langchain.prompts.few_shot import FewShotChatMessagePromptTemplate\n",
    "import logging\n",
    "llm=ChatOpenAI(\n",
    "    temperature=0.1,\n",
    "    streaming=True,\n",
    "    callbacks=[StreamingStdOutCallbackHandler()]\n",
    "               )\n",
    "memory=ConversationSummaryBufferMemory(\n",
    "    llm=llm,\n",
    "    max_token_limit=500,\n",
    "    memory_key=\"history\",\n",
    "    return_messages=True,\n",
    ")\n",
    "examples=[\n",
    "    {\n",
    "        \"ì˜í™”\":\"íŒŒë¬˜\",\n",
    "        \"answer\":\"âš°ï¸ğŸ‘»ğŸ”¦\",\n",
    "    },{\n",
    "        \"ì˜í™”\": \"ë‚˜í™€ë¡œì§‘ì—\",\n",
    "        \"answer\": \"ğŸ ğŸ„ğŸ˜‚\"\n",
    "    },{\n",
    "        \"ì˜í™”\": \"ë¤ì•¤ë”ë¨¸\",\n",
    "        \"answer\": \"ğŸ¤£ğŸš™ğŸ§¥\"\n",
    "    },\n",
    "]\n",
    "\n",
    "example_prompt=ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"human\",\"ì˜í™” {ì˜í™”}ì— ëŒ€í•´ ì´ë¯¸í‹°ì½˜ 3ê°œë¡œ í‘œí˜„í•´ì¤˜\"),\n",
    "        (\"ai\",\"{answer}\")\n",
    "    ]\n",
    ")\n",
    "example_prompt=FewShotChatMessagePromptTemplate(\n",
    "    example_prompt=example_prompt,\n",
    "    examples=examples\n",
    ")\n",
    "\n",
    "\n",
    "prompt=ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",\"You are a helpful AI talking to a human\"),\n",
    "        MessagesPlaceholder(variable_name=\"history\"),\n",
    "        example_prompt,\n",
    "        (\"human\",\"{question}\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "def load_memory(_):\n",
    "    return memory.load_memory_variables({})[\"history\"]\n",
    "\n",
    "chain=RunnablePassthrough.assign(history=load_memory) | prompt | llm\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "def get_movie_emoji(question):\n",
    "    response = chain.invoke({\"question\": question})\n",
    "    memory.save_context({\"input\": question}, {\"output\": response.content})\n",
    "    logging.info(f\"{question} -> {response.content}\\n\")\n",
    "\n",
    "# âœ… 7ï¸âƒ£ ì‹¤í–‰ í…ŒìŠ¤íŠ¸ (ë‘ ê°œì˜ ì˜í™” ì§ˆë¬¸ í›„, ì´ì „ ì§ˆë¬¸ í™•ì¸)\n",
    "get_movie_emoji(\"ì¸ì…‰ì…˜\")\n",
    "get_movie_emoji(\"íƒ€ì´íƒ€ë‹‰\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë‹¹ì‹ ì´ ì²˜ìŒ ë¬¼ì–´ë³¸ ì˜í™”ëŠ” 'ì¸ì…‰ì…˜'ì´ì—ˆìŠµë‹ˆë‹¤."
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessageChunk(content=\"ë‹¹ì‹ ì´ ì²˜ìŒ ë¬¼ì–´ë³¸ ì˜í™”ëŠ” 'ì¸ì…‰ì…˜'ì´ì—ˆìŠµë‹ˆë‹¤.\")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"question\":\"ë‚´ê°€ ì œì¼ ì²˜ìŒ ë¬¼ì–´ë³¸ ì˜í™”ëŠ”?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë§ˆì§€ë§‰ìœ¼ë¡œ ë¬¼ì–´ë³´ì‹  ì˜í™”ëŠ” \"ë¤ì•¤ë”ë¨¸\"ì…ë‹ˆë‹¤."
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessageChunk(content='ë§ˆì§€ë§‰ìœ¼ë¡œ ë¬¼ì–´ë³´ì‹  ì˜í™”ëŠ” \"ë¤ì•¤ë”ë¨¸\"ì…ë‹ˆë‹¤.')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"question\":\"ë‚´ê°€ ë§ˆì§€ë§‰ì— ë¬¼ì–´ë³¸ ì˜í™”ëŠ”?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'history': [HumanMessage(content='ì¸ì…‰ì…˜'), AIMessage(content='ğŸ’­ğŸŒŒğŸ”‘'), HumanMessage(content='íƒ€ì´íƒ€ë‹‰'), AIMessage(content='ğŸš¢ğŸ’”ğŸŒŠ')]}\n"
     ]
    }
   ],
   "source": [
    "print(memory.load_memory_variables({}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
